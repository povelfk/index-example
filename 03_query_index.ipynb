{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a2cddf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'demo'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "azure_openai_api_key = config.get(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_endpoint = config.get(\"AZURE_OPENAI_API_BASE\")\n",
    "azure_openai_api_version = config.get(\"AZURE_OPENAI_API_VERSION\")\n",
    "azure_openai_chat_model = config.get(\"AZURE_OPENAI_MODEL\")\n",
    "azure_openai_embedding_model = config.get(\"AZURE_OPENAI_EMBEDDING_MODEL\")\n",
    "\n",
    "search_credential = AzureKeyCredential(config.get(\"SEARCH_KEY\"))\n",
    "search_endpoint = config.get(\"SEARCH_ENDPOINT\")\n",
    "\n",
    "index_name = config.get(\"SEARCH_INDEX_NAME\")\n",
    "index_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf7bc76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchItemPaged\n",
    "\n",
    "def print_results(results: SearchItemPaged[dict]):\n",
    "    semantic_answers = results.get_answers()\n",
    "    if semantic_answers:\n",
    "        for answer in semantic_answers:\n",
    "            if answer.highlights:\n",
    "                print(f\"Semantic Answer: {answer.highlights}\")\n",
    "            else:\n",
    "                print(f\"Semantic Answer: {answer.text}\")\n",
    "            print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "    for result in results:\n",
    "        print(f\"Title: {result['title']}\")  \n",
    "        print(f\"Score: {result['@search.score']}\")\n",
    "        if result.get('@search.reranker_score'):\n",
    "            print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
    "        print(f\"Content: {result['content']}\")  \n",
    "\n",
    "        captions = result[\"@search.captions\"]\n",
    "        if captions:\n",
    "            caption = captions[0]\n",
    "            if caption.highlights:\n",
    "                print(f\"Caption: {caption.highlights}\\n\")\n",
    "            else:\n",
    "                print(f\"Caption: {caption.text}\\n\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2bce19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: 1706.03762v7.pdf_chunk_6\n",
      "Score: 0.5537048\n",
      "Content: We call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of queries and keys of dimension dk, and values of dimension dy. We compute the dot products of the query with all keys, divide each by Vdk, and apply a softmax function to obtain the weights on the :selected: values. In practice, we compute the attention function on a set of queries simultaneously, packed together into a matrix Q. The keys and values are also packed together into matrices K and V. We compute the matrix of outputs as: Attention(Q, K, V) = softmax( Vdk QKT V (1) The two most commonly used attention functions are additive attention [2], and dot-product (multi- plicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor of . Additive attention computes the compatibility function using a feed-forward network with :selected: Vdk a single hidden layer. While the two are similar in theoretical complexity, dot-product attention is much faster and more space-efficient in practice, since it can be implemented using highly optimized matrix multiplication code. While for small values of dk the two mechanisms perform similarly, additive attention outperforms dot product attention without scaling for larger values of dk [3]. We suspect that for large values of dk, the dot products grow large in magnitude, pushing the softmax function into regions where it has extremely small gradients 4. To counteract this effect, we scale the dot products by.\n",
      "\n",
      "Title: 1706.03762v7.pdf_chunk_20\n",
      "Score: 0.5518125\n",
      "Content: To evaluate the importance of different components of the Transformer, we varied our base model in different ways, measuring the change in performance on English-to-German translation on the 5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively. 8 Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base model. All metrics are on the English-to-German translation development set, newstest2013. Listed perplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to per-word perplexities. N dmodel dff h dk dv Pdrop Els train steps PPL (dev) BLEU (dev) params Ã—106 base 6 512 2048 8 64 64 0.1 0.1 100K 4.92 25.8 65 (A) 1 512 512 5.29 24.9 4 128 128 5.00 25.5 16 32 32 4.91 25.8 32 16 16 5.01 25.4 (B) 16 5.16 25.1 58 32 5.01 25.4 60 (C) 2 6.11 23.7 36 4 5.19 25.3 50 8 4.88 25.5 80 256 32 32 5.75 24.5 28 1024 128 128 4.66 26.0 168 1024 5.12 25.4 53 4096 4.75 26.2 90 (D) 0.0 5.77 24.6 0.2 4.95 25.5 0.0 4.67 25.3 0.2 5.47 25.7 (E) positional embedding instead of sinusoids 4.92 25.7 big 6 1024 4096 16 0.3 300K 4.33 26.4 213 development set, newstest2013. We used beam search as described in the previous section, but no checkpoint averaging. We present these results in Table 3. In Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions, keeping the amount of computation constant, as described in Section 3.2.2. While single-head attention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads. In Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This suggests that determining compatibility is not easy and that a more sophisticated compatibility function than dot product may be beneficial. We further observe in rows (C) and (D) that, as expected, bigger models are better, and dropout is very helpful in avoiding over-fitting. In row (E) we replace our sinusoidal positional encoding with learned positional embeddings [9], and observe nearly identical results to the base model.\n",
      "\n",
      "Title: 1706.03762v7.pdf_chunk_26\n",
      "Score: 0.5516447\n",
      "Content: the word 'making'. Different colors represent different heads. Best viewed in color. Figure 3: An example of the attention mechanism following long-distance dependencies in the encoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of the verb 'making', completing the phrase 'making ... more difficult'. Attentions here shown only for It It is is in in this this spirit spirit that that a a majority majority of American of American governments governments have passed have passed new new laws laws since since 2009 2009 making making the registration the registration or voting process or voting process more more difficult difficult . . <EOS> <EOS> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 13 and 6. Note that the attentions are very sharp for this word. Full attentions for head 5. Bottom: Isolated attentions from just the word 'its' for attention heads 5 Figure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top: The The Law The The Law Law Law will will will will never be perfect never never never be be be perfect perfect perfect , , but , but its but , but its its its application application should application should application should should be be be be just just just just - - - - this this this this is is is is what what what what we we we we are are are are missing missing missing missing , in my , in , , in in my my my opinion opinion opinion opinion . . . . <EOS> <EOS> <EOS> <EOS> <pad> <pad> <pad> <pad> 14 The The Law Law will will never never be be perfect perfect , but , but its its application should application should be be just just - - this this is is what what we we are are missing missing , , in in my my opinion opinion . . <EOS> <EOS> <pad> <pad> The The Law Law will will never never be be perfect perfect , but , but its its application application should should be be just just - - this this is is what what we we are are missing missing , , in in my my opinion opinion . . <EOS> <EOS> <pad> <pad> Figure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the sentence. We give two such examples above, from two different heads from the encoder self-attention at layer 5 of 6. The heads clearly learned to perform different tasks. 15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.models import VectorizedQuery\n",
    "from openai import AzureOpenAI\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "search_client = SearchClient(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=index_name,\n",
    "    credential=search_credential\n",
    ")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key = azure_openai_api_key,  \n",
    "  api_version = azure_openai_api_version,\n",
    "  azure_endpoint = azure_openai_endpoint\n",
    ")\n",
    "\n",
    "# Pure Vector Search\n",
    "query = \"*\"\n",
    "embedding = client.embeddings.create(input=query, model=azure_openai_embedding_model, dimensions=3072).data[0].embedding\n",
    "\n",
    "# 50 is an optimal value for k_nearest_neighbors when performing vector search\n",
    "# To learn more about how vector ranking works, please visit https://learn.microsoft.com/azure/search/vector-search-ranking\n",
    "vector_query = VectorizedQuery(vector=embedding, k_nearest_neighbors=50, fields=\"text_vector\")\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"title\", \"content\"],\n",
    "    top=3\n",
    ")\n",
    "\n",
    "\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eb9bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pisa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
